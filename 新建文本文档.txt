a. 观察主回归方程分析报告：建立主回归方程，分析回归报告结果。
    * 主回归分析报告的$R^2$值高（大于0.8），$F^{\ast}$检验显著，但不显著的$t^\ast$检验较多（多于回归系数个数的一半及以上）
a. 矩阵相关系数和矩阵散点图：绘制回归元之间的相关系数矩阵和散点图矩阵。
    * 相关系数矩阵发现高度线性相关（相关系数大于0.8）
    * 散点图矩阵发现高度线性相关的数据分布模式
a. 分析辅助回归方程：首先构建主回归方程，然后分别构建回归元之间的辅助回归方程。
    * 辅助回归方程的判定系数$R^2_j$大于主回归方程的判定系数$R^2$
    * 辅助回归方程的方差膨胀因子：$VIF_j\in[10,100]$表明中度多重共线性；$VIF_j\geq{100}$表明严重多重共线性
    * 辅助回归方程的的容许度：$TOL_j\in[0.01,0.1]$表明中度多重共线性；$TOL_j\leq{0.01}$表明严重多重共线性
a. 主成分分析法(principal components)：计算特征值(eigenvalues)，进而得到病态数($k$)和病态指数$CI=\sqrt{k}$
    * 病态数：$k \in[100,1000]$表明中度多重共线性；$k \geq{1000}$表明严重多重共线性
    * 病态指数：$CI \in[10,30]$表明中度多重共线性；$CI \geq{30}$表明严重多重共线性

## 多重共线性修正方法：
a. 简单剔除变量法：
    * 依据经济学和实践经验观察，进行变量甄选或变量变换
a. 逐步回归法：包括前向逐步回归(forward stepwise)和后向逐步回归(backward stepwise)
    * p值判别法：$p\in[0.1,0.05)$(比较显著)；$p\in[0.05,0.01)$(比较显著)；$p\leq 0.01$(极其显著)
    * $t^{\ast}$值判别法：2t法则
a. 补充新数据（有时候有用！）
    * 由于多重共线性是一个样本特性，故有可能在关于同样变量的另一样本中共线性没有第一个样本那么严重
a. 多项式回归模型中离差形式或正交多项式(orthogonal polynomials)以降低共线性的影响
    * 多项式回归模型的一个特点是解释变量以不同的幂出现，从而容易导致多重共线性
a. 拯救多重共线性的其他方法
    + 脊回归(ridge regression) 常被用来"解决"多重共线性问题。
    + 主成分分析法
        + 先根据主成分分析确定主成分个数(看累积解释百分比)
        + 再用主成分得分（scoring）序列进行回归分析
